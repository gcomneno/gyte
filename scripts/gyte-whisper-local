#!/usr/bin/env bash
set -euo pipefail

# Uso:
#   gyte-whisper-local [--model MODEL] [--lang LANG] [--outdir DIR] [--backend B] FILE
#
# Scopo:
# - Trascrizione locale con whisper.cpp / faster-whisper / whisper (a seconda del tuo setup)
# - Output: file .txt nella outdir (o stessa dir), nome derivato da input
#
# Nota:
# - Script "optional": dipendenze pesanti NON obbligatorie per GYTE base.

PROG="gyte-whisper-local"

MODEL="${GYTE_WHISPER_MODEL:-}"
LANG="${GYTE_WHISPER_LANG:-}"
OUTDIR="${GYTE_OUTDIR:-}"
BACKEND="${GYTE_WHISPER_BACKEND:-auto}"  # auto|whispercpp|faster|openai|unknown

usage() {
  cat <<EOF
Uso:
  $PROG [--model MODEL] [--lang LANG] [--outdir DIR] [--backend B] FILE

Opzioni:
  --model MODEL   modello whisper (dipende dal backend)
  --lang  LANG    lingua (es: it, en) (opzionale)
  --outdir DIR    directory output (default: stessa dir del file)
  --backend B     auto|whispercpp|faster|openai (default: auto)
  -h, --help      help
EOF
}

# Exit code policy:
# - 2: usage/parsing errors
# - 1: runtime/user-env errors
die_usage(){ echo "ERRORE: $*" >&2; exit 2; }
die_runtime(){ echo "ERRORE: $*" >&2; exit 1; }

need(){ command -v "$1" >/dev/null 2>&1 || die_runtime "comando richiesto non trovato: $1"; }

# Parse args
while (( $# > 0 )); do
  case "$1" in
    --model)
      (( $#>=2 )) || die_usage "--model richiede MODEL"
      MODEL="$2"
      shift 2
      ;;
    --model=*)
      MODEL="${1#*=}"
      shift
      ;;
    --lang)
      (( $#>=2 )) || die_usage "--lang richiede LANG"
      LANG="$2"
      shift 2
      ;;
    --lang=*)
      LANG="${1#*=}"
      shift
      ;;
    --outdir)
      (( $#>=2 )) || die_usage "--outdir richiede DIR"
      OUTDIR="$2"
      shift 2
      ;;
    --outdir=*)
      OUTDIR="${1#*=}"
      shift
      ;;
    --backend)
      (( $#>=2 )) || die_usage "--backend richiede VALORE"
      BACKEND="$2"
      shift 2
      ;;
    --backend=*)
      BACKEND="${1#*=}"
      shift
      ;;
    -h|--help)
      usage
      exit 0
      ;;
    *)
      break
      ;;
  esac
done

FILE="${1:-}"
[[ -n "$FILE" ]] || { usage; exit 2; }
[[ -f "$FILE" ]] || die_runtime "file non trovato: $FILE"

if [[ -z "$OUTDIR" ]]; then
  OUTDIR="$(cd -- "$(dirname -- "$FILE")" && pwd)"
fi
mkdir -p -- "$OUTDIR"

base="$(basename -- "$FILE")"
stem="${base%.*}"
OUT_TXT="$OUTDIR/$stem.txt"

# Backend discovery (best-effort)
STT_BIN=""

if command -v whisper.cpp >/dev/null 2>&1; then
  STT_BIN="whisper.cpp"
elif command -v whisper-cpp >/dev/null 2>&1; then
  STT_BIN="whisper-cpp"
elif command -v faster-whisper >/dev/null 2>&1; then
  STT_BIN="faster-whisper"
elif command -v whisper >/dev/null 2>&1; then
  STT_BIN="whisper"
fi

# FIX SC2166: no [ p -o q ]
if [ -n "$STT_BIN" ] && { [ "$BACKEND" = "auto" ] || [ "$BACKEND" = "unknown" ]; }; then
  case "$STT_BIN" in
    whisper.cpp|whisper-cpp)
      BACKEND="whispercpp"
      ;;
    faster-whisper)
      BACKEND="faster"
      ;;
    whisper)
      BACKEND="openai"
      ;;
    *)
      BACKEND="unknown"
      ;;
  esac
fi

case "$BACKEND" in
  whispercpp|faster|openai|auto|unknown)
    ;;
  *)
    die_usage "--backend non valido: $BACKEND"
    ;;
esac

# Defaults (backend-specific)
if [[ -z "$MODEL" ]]; then
  # model naming differs; keep empty -> backend default
  MODEL=""
fi

# Se abbiamo un backend “vero”, STT_BIN deve esistere.
case "$BACKEND" in
  whispercpp|faster|openai)
    [[ -n "$STT_BIN" ]] || die_runtime "backend '$BACKEND' richiesto ma nessun binario STT trovato nel PATH"
    need "$STT_BIN"
    ;;
esac

# Execute
case "$BACKEND" in
  whispercpp)
    # Typical whisper.cpp CLI:
    #   whisper.cpp -m model.bin -f input -l it -otxt -of outprefix
    OUT_PREFIX="$OUTDIR/$stem"
    args=()
    if [[ -n "$MODEL" ]]; then
      args+=(-m "$MODEL")
    fi
    args+=(-f "$FILE" -otxt -of "$OUT_PREFIX")
    if [[ -n "$LANG" ]]; then
      args+=(-l "$LANG")
    fi
    "$STT_BIN" "${args[@]}" >/dev/null
    # whisper.cpp typically outputs OUT_PREFIX.txt
    [[ -s "${OUT_PREFIX}.txt" ]] || die_runtime "output mancante o vuoto: ${OUT_PREFIX}.txt"
    mv -f "${OUT_PREFIX}.txt" "$OUT_TXT"
    ;;
  faster)
    args=("$FILE" "--output_dir" "$OUTDIR" "--output_format" "txt")
    if [[ -n "$MODEL" ]]; then
      args+=("--model" "$MODEL")
    fi
    if [[ -n "$LANG" ]]; then
      args+=("--language" "$LANG")
    fi
    "$STT_BIN" "${args[@]}" >/dev/null
    # faster-whisper outputs "$stem.txt" in OUTDIR
    [[ -s "$OUT_TXT" ]] || die_runtime "output mancante o vuoto: $OUT_TXT"
    ;;
  openai)
    # If user has python openai-whisper installed and uses "whisper" CLI.
    args=("$FILE" "--output_dir" "$OUTDIR" "--output_format" "txt")
    if [[ -n "$MODEL" ]]; then
      args+=("--model" "$MODEL")
    fi
    if [[ -n "$LANG" ]]; then
      args+=("--language" "$LANG")
    fi
    "$STT_BIN" "${args[@]}" >/dev/null
    [[ -s "$OUT_TXT" ]] || die_runtime "output mancante o vuoto: $OUT_TXT"
    ;;
  auto|unknown)
    die_runtime "backend non determinato (nessun whisper trovato nel PATH). Installa whisper.cpp o faster-whisper."
    ;;
esac

# Output path on stdout (useful for chaining)
echo "$OUT_TXT"
